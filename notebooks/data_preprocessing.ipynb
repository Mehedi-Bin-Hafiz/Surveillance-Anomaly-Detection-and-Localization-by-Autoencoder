{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc8328a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c478d6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "taken_fps = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e30be7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taken_frames_durations(cap, saving_fps):\n",
    "    duration = []\n",
    "    video_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n",
    "    for i in np.arange(0, video_duration, 1 / saving_fps):\n",
    "        duration.append(round(i,2))\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3c40599",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_image = list()\n",
    "video_directory = \"D:\\\\Research Dataset\\\\Surveillance\\\\Train\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44170b78",
   "metadata": {},
   "source": [
    "## Frame extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e49a1538",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_names = os.listdir(video_directory) \n",
    "for name in video_names:\n",
    "    saving_dir_name, _ = os.path.splitext(name)\n",
    "    saving_dir_name = \"video_\" + saving_dir_name\n",
    "    video_path = os.path.join(video_directory, name)\n",
    "    cap = cv2.VideoCapture(video_path) \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    final_taken_fps = min(fps, taken_fps) # taken_fps should not higher than video fps\n",
    "    saving_frames_durations = taken_frames_durations(cap, final_taken_fps)\n",
    "    time_count = 0\n",
    "    frame_number = 0\n",
    "    while True:\n",
    "        is_read, frame = cap.read()\n",
    "        if not is_read:\n",
    "            break\n",
    "        frame_duration = time_count / fps # measure duration until video end\n",
    "        try:\n",
    "            closest_duration = saving_frames_durations[0]\n",
    "        except:\n",
    "            break\n",
    "        if frame_duration >= closest_duration: #this condition maintain taken 10 fps\n",
    "            frame = cv2.resize(frame,(232,232), interpolation = cv2.INTER_AREA)\n",
    "            frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "            store_image.append(frame)\n",
    "            frame_number += 1\n",
    "            try:\n",
    "                saving_frames_durations.pop(0) #as 0th postion recored so I removed 0th frame\n",
    "            except:\n",
    "                pass\n",
    "        time_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "500bcf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 232, 232)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_image2=np.array(store_image)\n",
    "store_image2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bb263ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, 232, 67)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b,c=store_image2.shape #a is number of frames, b c is size\n",
    "store_image3 = np.moveaxis(store_image2, 0, -1) #need to make shape (227,227,frames)\n",
    "store_image3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f60663",
   "metadata": {},
   "source": [
    "## Normalization and data saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c14754bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_image3=(store_image3-store_image3.mean())/(store_image3.std())\n",
    "store_image3=np.clip(store_image3,0,1)\n",
    "np.save('../dataset/training.npy',store_image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab53f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f566c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01070983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b476d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c30dade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb56821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
