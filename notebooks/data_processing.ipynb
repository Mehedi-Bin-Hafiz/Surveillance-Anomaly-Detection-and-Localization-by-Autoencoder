{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378c9b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 videos in 'D:\\Research Dataset\\Surveillance\\Train'\n",
      "Processing video: training_video.mp4 (FPS: 30.00, Target Sampled FPS: 10)\n",
      "\n",
      "Finished processing all videos. Total frames collected: 67\n",
      "Shape of collected frames before normalization: (67, 232, 232, 1)\n",
      "Shape of collected frames after normalization: (67, 232, 232, 1)\n",
      "Min pixel value after normalization: -1.0000\n",
      "Max pixel value after normalization: 1.0000\n",
      "Saved processed training data to '../dataset\\training_frames.npy'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Placeholder for taken_frames_durations ---\n",
    "# Please replace this with your actual implementation of taken_frames_durations.\n",
    "# This function should return a list of durations (in seconds) at which to capture frames.\n",
    "def taken_frames_durations(cap, target_fps):\n",
    "    \"\"\"\n",
    "    Generates a list of target durations for frame capture.\n",
    "    (Placeholder - replace with your actual logic)\n",
    "    \"\"\"\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    if fps == 0: # Avoid division by zero if fps is not available\n",
    "        return []\n",
    "    \n",
    "    durations = []\n",
    "    # Example: capture a frame every (1/target_fps) seconds\n",
    "    # This might need adjustment based on your original taken_frames_durations logic\n",
    "    interval = 1.0 / target_fps\n",
    "    current_duration = 0.0\n",
    "    while current_duration < (total_frames / fps):\n",
    "        durations.append(current_duration)\n",
    "        current_duration += interval\n",
    "    return durations\n",
    "# --- End Placeholder ---\n",
    "\n",
    "\n",
    "taken_fps = 10 # This now refers to the target frames per second to sample\n",
    "store_image = list()\n",
    "video_directory = \"D:\\\\Research Dataset\\\\Surveillance\\\\Train\" # Directory containing your training videos\n",
    "\n",
    "# Ensure the dataset directory exists\n",
    "dataset_output_dir = '../dataset'\n",
    "if not os.path.exists(dataset_output_dir):\n",
    "    os.makedirs(dataset_output_dir)\n",
    "\n",
    "video_names = os.listdir(video_directory) \n",
    "print(f\"Found {len(video_names)} videos in '{video_directory}'\")\n",
    "\n",
    "for name in video_names:\n",
    "    video_path = os.path.join(video_directory, name)\n",
    "    cap = cv2.VideoCapture(video_path) \n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Warning: Could not open video file: {video_path}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    if fps == 0:\n",
    "        print(f\"Warning: FPS is 0 for video: {video_path}. Skipping.\")\n",
    "        cap.release()\n",
    "        continue\n",
    "\n",
    "    final_taken_fps = min(fps, taken_fps) # taken_fps should not higher than video fps\n",
    "    saving_frames_durations = taken_frames_durations(cap, final_taken_fps)\n",
    "    \n",
    "    time_count = 0\n",
    "    frame_number = 0\n",
    "    \n",
    "    print(f\"Processing video: {name} (FPS: {fps:.2f}, Target Sampled FPS: {final_taken_fps})\")\n",
    "\n",
    "    while True:\n",
    "        is_read, frame = cap.read()\n",
    "        if not is_read:\n",
    "            break # End of video\n",
    "\n",
    "        frame_duration = time_count / fps # measure duration until video end\n",
    "        \n",
    "        # Check if there are durations left to process\n",
    "        if not saving_frames_durations:\n",
    "            break # No more specific durations to save frames at\n",
    "\n",
    "        closest_duration = saving_frames_durations[0]\n",
    "        \n",
    "        if frame_duration >= closest_duration: #this condition maintain taken 10 fps\n",
    "            # Resize frame to the model's expected input dimensions (232x232)\n",
    "            frame = cv2.resize(frame, (232, 232), interpolation = cv2.INTER_AREA)\n",
    "            # Convert to grayscale\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Store the grayscale frame.\n",
    "            # Normalization to [-1, 1] will be applied after collecting all frames,\n",
    "            # or can be done here if preferred for streaming data.\n",
    "            store_image.append(frame)\n",
    "            \n",
    "            frame_number += 1\n",
    "            \n",
    "            try:\n",
    "                saving_frames_durations.pop(0) # Remove the duration that has been processed\n",
    "            except IndexError:\n",
    "                # This should ideally not happen if the loop breaks when saving_frames_durations is empty\n",
    "                pass\n",
    "        time_count += 1\n",
    "    \n",
    "    cap.release() # Release the video capture object after processing each video\n",
    "\n",
    "print(f\"\\nFinished processing all videos. Total frames collected: {len(store_image)}\")\n",
    "\n",
    "# Convert the list of frames to a NumPy array\n",
    "# The shape will be (number_of_frames, height, width) -> (num_frames, 232, 232)\n",
    "store_image_np = np.array(store_image, dtype=np.float32)\n",
    "\n",
    "# Add a channel dimension for grayscale images, making the shape (num_frames, 232, 232, 1)\n",
    "# This is the standard input shape for many Keras/TensorFlow models for single images.\n",
    "store_image_final = np.expand_dims(store_image_np, axis=-1)\n",
    "\n",
    "print(f\"Shape of collected frames before normalization: {store_image_final.shape}\")\n",
    "\n",
    "# Normalize pixel values to the range [-1, 1]\n",
    "# This normalization is applied to the entire dataset.\n",
    "# Ensure your model's input layer expects values in this range.\n",
    "if store_image_final.size > 0: # Avoid division by zero if no images were stored\n",
    "    mean_val = store_image_final.mean()\n",
    "    std_val = store_image_final.std()\n",
    "    \n",
    "    if std_val == 0: # Handle cases where std dev is zero (e.g., all black frames)\n",
    "        print(\"Warning: Standard deviation is zero. Setting normalized frames to 0.\")\n",
    "        store_image_final_normalized = np.zeros_like(store_image_final)\n",
    "    else:\n",
    "        store_image_final_normalized = (store_image_final - mean_val) / std_val\n",
    "    \n",
    "    # Clip values to a reasonable range, e.g., [-1, 1] or [0, 1] if your model expects that.\n",
    "    # The original code clipped to [0,1], but (x-mean)/std can go outside this.\n",
    "    # If the model expects [-1,1] from (gray - 0.5) * 2, then this clipping might need adjustment.\n",
    "    # For now, let's keep it consistent with the previous preprocess_frame_for_new_model\n",
    "    # which normalizes to [-1, 1].\n",
    "    store_image_final_normalized = (store_image_final_normalized - store_image_final_normalized.min()) / \\\n",
    "                                   (store_image_final_normalized.max() - store_image_final_normalized.min())\n",
    "    store_image_final_normalized = (store_image_final_normalized - 0.5) * 2\n",
    "    \n",
    "    # It's important to clip after normalization if values can go out of expected range.\n",
    "    # The original code used np.clip(..., 0, 1) after (x-mean)/std, which is unusual.\n",
    "    # Let's ensure the final range is consistent with the model's preprocessing.\n",
    "    # If the model expects [-1, 1], then ensure the training data is also in this range.\n",
    "    # The preprocess_frame_for_new_model uses (gray - 0.5) * 2 which results in [-1, 1].\n",
    "    # So, let's ensure the saved training data also adheres to this.\n",
    "    # The above normalization to [-1,1] is good.\n",
    "    \n",
    "    # If you want to strictly clip to [-1, 1] after the above normalization:\n",
    "    store_image_final_normalized = np.clip(store_image_final_normalized, -1, 1)\n",
    "\n",
    "    print(f\"Shape of collected frames after normalization: {store_image_final_normalized.shape}\")\n",
    "    print(f\"Min pixel value after normalization: {np.min(store_image_final_normalized):.4f}\")\n",
    "    print(f\"Max pixel value after normalization: {np.max(store_image_final_normalized):.4f}\")\n",
    "    \n",
    "    # Save the processed and normalized frames\n",
    "    np.save(os.path.join(dataset_output_dir, 'training_frames.npy'), store_image_final_normalized)\n",
    "    print(f\"Saved processed training data to '{os.path.join(dataset_output_dir, 'training_frames.npy')}'\")\n",
    "else:\n",
    "    print(\"No frames were collected. 'training_frames.npy' will not be saved.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
